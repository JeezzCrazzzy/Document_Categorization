{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzsRr8fN_BJu"
      },
      "source": [
        "# 1. Setup and Install Dependencies\n",
        "\n",
        "\n",
        "*   Install required libraries such as datasets, evaluate, and seqeval for  \n",
        "    model training and evaluation.\n",
        "*   Import necessary Python libraries including PyTorch, Transformers, and datasets.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfujolSkOMcd",
        "outputId": "69da1b50-c407-4d05-8cfa-f22f528baa0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.11/dist-packages (1.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.14)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.29.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.6.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets evaluate seqeval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoQmj6-G_lmP"
      },
      "source": [
        "# 2. Load Required Modules\n",
        "\n",
        "\n",
        "*  Import PyTorch components for model building and training.\n",
        "*  Load Transformers' modules for tokenization, model loading, and data processing.\n",
        "*  Load dataset handling utilities from datasets.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUXC9SCXIpeb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torch.optim import AdamW\n",
        "from transformers import (\n",
        "    AutoProcessor, AutoTokenizer, DistilBertTokenizer,\n",
        "    DistilBertForTokenClassification, LayoutLMv3ForTokenClassification,\n",
        "    default_data_collator, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        ")\n",
        "from datasets import load_dataset, Features, Sequence, Value, Array2D, Array3D\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WemOMHy6AHmg"
      },
      "source": [
        "# 3. Set Device\n",
        "\n",
        "Determine if a GPU is available; otherwise, use the CPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0g1AbCp7AeJ"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52O4qVikANjc"
      },
      "source": [
        "# 4. Load Teacher and Student Tokenizers\n",
        "\n",
        "Load the processor and tokenizer for the teacher model (LayoutLMv3) and the tokenizer for the student model (DistilBERT)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRElhA80IjT1",
        "outputId": "ad9f7313-e956-41e1-d5b3-99a10f416f55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "processor = AutoProcessor.from_pretrained(\"microsoft/layoutlmv3-base\", apply_ocr=False)\n",
        "teacher_tokenizer = AutoTokenizer.from_pretrained(\"microsoft/layoutlmv3-base\")\n",
        "student_tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUmx6ZbCAgA0"
      },
      "source": [
        "# 5. Load and Process Dataset\n",
        "* Load the FUNSD dataset for layout-aware token classification.\n",
        "\n",
        "* Extract label mappings from the dataset.\n",
        "\n",
        "* Define column names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFgGHegEIa5k"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"nielsr/funsd-layoutlmv3\")\n",
        "label_list = dataset['train'].features['ner_tags'].feature.names\n",
        "id2label = {k: v for k, v in enumerate(label_list)}\n",
        "label2id = {v: k for k, v in enumerate(label_list)}\n",
        "num_labels = len(label_list)\n",
        "\n",
        "image_column_name = \"image\"\n",
        "text_column_name = \"tokens\"\n",
        "boxes_column_name = \"bboxes\"\n",
        "label_column_name = \"ner_tags\"\n",
        "column_names = dataset[\"train\"].column_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eRK9QTQA24Y"
      },
      "source": [
        "# 6. Define Example Preparation Functions\n",
        "\n",
        "* Create functions for tokenizing teacher and student data.\n",
        "\n",
        "* The teacher model uses images, text, and bounding boxes.\n",
        "\n",
        "* The student model uses only text and includes dummy bounding boxes and pixel values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HgOW1ExKIVbD"
      },
      "outputs": [],
      "source": [
        "def prepare_examples(examples):\n",
        "    encoding = processor(\n",
        "        examples[image_column_name],\n",
        "        examples[text_column_name],\n",
        "        max_length=teacher_tokenizer.model_max_length,\n",
        "        boxes=examples[boxes_column_name],\n",
        "        word_labels=examples[label_column_name],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\"\n",
        "    )\n",
        "    return encoding\n",
        "\n",
        "def student_prepare_examples(examples):\n",
        "    encoding = student_tokenizer(\n",
        "        examples[text_column_name],\n",
        "        is_split_into_words=True,\n",
        "        max_length=teacher_tokenizer.model_max_length,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\"\n",
        "    )\n",
        "    encoding[\"bbox\"] = [[[0, 0, 0, 0]] * teacher_tokenizer.model_max_length] * len(encoding[\"input_ids\"])\n",
        "    encoding[\"pixel_values\"] = [np.zeros((3, 224, 224), dtype=\"float32\").tolist()] * len(encoding[\"input_ids\"])\n",
        "    encoding[\"labels\"] = [label + [-100] * (teacher_tokenizer.model_max_length - len(label)) for label in examples[label_column_name]]\n",
        "    return encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ap8H-sEvBFvj"
      },
      "source": [
        "# 7. Prepare Datasets for Training and Evaluation\n",
        "\n",
        "* Convert the dataset into a format compatible with LayoutLMv3 and DistilBERT.\n",
        "\n",
        "* Apply transformations to the dataset for teacher model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "9cfc8df6e0ea45f78ffb71b25f1d8a50",
            "921cd6a9f2e343cbacb9fe93cd2fce44",
            "1ee7a0949aa74a42bb503e05f7f3f6c5",
            "39060935d34a453fa54bd246d4450a02",
            "8136a9865583446bb190a0c04ae5c3d1",
            "fc6ef84d484541658c2a0b43a61748fc",
            "bb25f853143141b1a2e6aba5e67cdac7",
            "d6df77999b95454689c4920c661ab563",
            "90ce471dc88947aabf3d969ec0fc21f7",
            "3c38d59a3f6945a6b06355b3608c20d0",
            "686af2b5d76b4e4fa765f0b7a32f4fc8"
          ]
        },
        "id": "VT9NKAnPNEPZ",
        "outputId": "c33240d0-8ff9-48e5-cb90-f377404d9188"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/30 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9cfc8df6e0ea45f78ffb71b25f1d8a50"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "features = Features({\n",
        "    'pixel_values': Array3D(dtype=\"float32\", shape=(3, 224, 224)),\n",
        "    'input_ids': Sequence(Value(dtype='int64')),\n",
        "    'attention_mask': Sequence(Value(dtype='int64')),\n",
        "    'bbox': Array2D(dtype=\"int64\", shape=(teacher_tokenizer.model_max_length, 4)),\n",
        "    'labels': Sequence(Value(dtype='int64')),\n",
        "})\n",
        "\n",
        "train_sample = dataset[\"train\"].shuffle(seed=42).select(range(60))\n",
        "\n",
        "train_dataset = train_sample.map(\n",
        "    prepare_examples,\n",
        "    batched=True,\n",
        "    remove_columns=column_names,\n",
        "    features=features,\n",
        ")\n",
        "test_sample = dataset[\"test\"].shuffle(seed=42).select(range(30))\n",
        "eval_dataset = test_sample.map(\n",
        "    prepare_examples,\n",
        "    batched=True,\n",
        "    remove_columns=column_names,\n",
        "    features=features,\n",
        ")\n",
        "validation_sample = dataset[\"test\"].shuffle(seed=42).select(range(10))\n",
        "validation_dataset = validation_sample.map(\n",
        "    prepare_examples,\n",
        "    batched=True,\n",
        "    remove_columns=column_names,\n",
        "    features=features,\n",
        ")\n",
        "\n",
        "train_dataset.set_format(\"torch\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHYfSvcTBQBc"
      },
      "source": [
        "# 8. Load Teacher Model\n",
        "Load the LayoutLMv3 model and set it to evaluation mode."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPJmF5NgVtly",
        "outputId": "f3eb43f1-cd37-4fe6-cd5e-d6ad7d1d7fe8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of LayoutLMv3ForTokenClassification were not initialized from the model checkpoint at microsoft/layoutlmv3-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LayoutLMv3ForTokenClassification(\n",
              "  (layoutlmv3): LayoutLMv3Model(\n",
              "    (embeddings): LayoutLMv3TextEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (x_position_embeddings): Embedding(1024, 128)\n",
              "      (y_position_embeddings): Embedding(1024, 128)\n",
              "      (h_position_embeddings): Embedding(1024, 128)\n",
              "      (w_position_embeddings): Embedding(1024, 128)\n",
              "    )\n",
              "    (patch_embed): LayoutLMv3PatchEmbeddings(\n",
              "      (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
              "    )\n",
              "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "    (encoder): LayoutLMv3Encoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x LayoutLMv3Layer(\n",
              "          (attention): LayoutLMv3Attention(\n",
              "            (self): LayoutLMv3SelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): LayoutLMv3SelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): LayoutLMv3Intermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): LayoutLMv3Output(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (rel_pos_bias): Linear(in_features=32, out_features=12, bias=False)\n",
              "      (rel_pos_x_bias): Linear(in_features=64, out_features=12, bias=False)\n",
              "      (rel_pos_y_bias): Linear(in_features=64, out_features=12, bias=False)\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "teacher_model = LayoutLMv3ForTokenClassification.from_pretrained(\n",
        "    \"microsoft/layoutlmv3-base\",\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ").to(device)\n",
        "teacher_model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIIHm3fbISZM"
      },
      "source": [
        "# 9. Fine-Tune the Teacher Model Using Hugging Face Trainer\n",
        "Purpose:\n",
        " * Fine-tune the pre-trained teacher model on the dataset using the Trainer API.\n",
        "\n",
        "Details:\n",
        "\n",
        "* Loads the teacher model (LayoutLMv3) for token classification.\n",
        "\n",
        "* Defines TrainingArguments such as output directory, batch sizes, learning rate, evaluation strategy, and number of steps.\n",
        "\n",
        "* Implements a compute_metrics function to evaluate model performance during training.\n",
        "\n",
        "* Initializes the Trainer with the teacher model, training/evaluation datasets, data collator, tokenizer (processor), and metric computation function.\n",
        "\n",
        "* Calls trainer.train() to fine-tune the teacher model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "id": "p1GUcgrVIl9H",
        "outputId": "6ccb0b30-1078-451c-a085-dbe7b6463865"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "<ipython-input-25-4e91272f4921>:54: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjayawasthi891\u001b[0m (\u001b[33mjayawasthi891-lnmiit\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250402_202320-34toscun</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/jayawasthi891-lnmiit/huggingface/runs/34toscun' target=\"_blank\">layoutlmv3-finetuned-cord_100</a></strong> to <a href='https://wandb.ai/jayawasthi891-lnmiit/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/jayawasthi891-lnmiit/huggingface' target=\"_blank\">https://wandb.ai/jayawasthi891-lnmiit/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/jayawasthi891-lnmiit/huggingface/runs/34toscun' target=\"_blank\">https://wandb.ai/jayawasthi891-lnmiit/huggingface/runs/34toscun</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:1589: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1000/1000 13:03, Epoch 66/67]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.707841</td>\n",
              "      <td>0.834217</td>\n",
              "      <td>0.892308</td>\n",
              "      <td>0.862285</td>\n",
              "      <td>0.711489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.276100</td>\n",
              "      <td>1.797852</td>\n",
              "      <td>0.872783</td>\n",
              "      <td>0.916599</td>\n",
              "      <td>0.894155</td>\n",
              "      <td>0.736207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.276100</td>\n",
              "      <td>1.865106</td>\n",
              "      <td>0.867030</td>\n",
              "      <td>0.902834</td>\n",
              "      <td>0.884570</td>\n",
              "      <td>0.749852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.006900</td>\n",
              "      <td>1.903015</td>\n",
              "      <td>0.870543</td>\n",
              "      <td>0.909312</td>\n",
              "      <td>0.889505</td>\n",
              "      <td>0.752027</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:1589: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1000, training_loss=0.14153105878829955, metrics={'train_runtime': 787.4481, 'train_samples_per_second': 5.08, 'train_steps_per_second': 1.27, 'total_flos': 1054421372928000.0, 'train_loss': 0.14153105878829955, 'epoch': 66.66666666666667})"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "import evaluate\n",
        "import numpy as np\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers.data.data_collator import default_data_collator\n",
        "\n",
        "metric = evaluate.load('seqeval')\n",
        "return_entity_level_metrics = False\n",
        "\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "    # Remove ignored index (special tokens)\n",
        "    true_predictions = [\n",
        "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "    if return_entity_level_metrics:\n",
        "        # Unpack nested dictionaries\n",
        "        final_results = {}\n",
        "        for key, value in results.items():\n",
        "            if isinstance(value, dict):\n",
        "                for n, v in value.items():\n",
        "                    final_results[f\"{key}_{n}\"] = v\n",
        "            else:\n",
        "                final_results[key] = value\n",
        "        return final_results\n",
        "    else:\n",
        "        return {\n",
        "            \"precision\": results[\"overall_precision\"],\n",
        "            \"recall\": results[\"overall_recall\"],\n",
        "            \"f1\": results[\"overall_f1\"],\n",
        "            \"accuracy\": results[\"overall_accuracy\"],\n",
        "        }\n",
        "\n",
        "training_args = TrainingArguments(output_dir=\"layoutlmv3-finetuned-cord_100\",\n",
        "                                  max_steps=1000,\n",
        "                                  per_device_train_batch_size=4,\n",
        "                                  per_device_eval_batch_size=4,\n",
        "                                  # push_to_hub=True,  # after training, we'd like to push our model to the hub\n",
        "                                  # push_to_hub_model_id=f\"layoutlmv3-finetuned-cord_100\",\n",
        "                                  learning_rate=1e-5,\n",
        "                                  evaluation_strategy=\"steps\",\n",
        "                                  eval_steps=250,\n",
        "                                  load_best_model_at_end=True,\n",
        "                                  metric_for_best_model=\"accuracy\")\n",
        "\n",
        "# Initialize our Trainer\n",
        "trainer = Trainer(\n",
        "    model=teacher_model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    tokenizer=processor,\n",
        "    data_collator=default_data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "student_model.save_pretrained(\"layoutlmv3_teacher_model\")"
      ],
      "metadata": {
        "id": "1AtE-7lmOMJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7j8TE5vgJWPI"
      },
      "source": [
        "# 10. Prepare Student Datasets for Training and Evaluation\n",
        "* **Convert** the dataset into a format compatible with DistilBERT.\n",
        "\n",
        "* Apply transformations to the dataset for student model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H537VUnKJi-i"
      },
      "outputs": [],
      "source": [
        "train_sample = dataset[\"train\"].shuffle(seed=42).select(range(60))\n",
        "student_train_dataset = train_sample.map(\n",
        "    student_prepare_examples,\n",
        "    batched=True,\n",
        "    remove_columns=column_names,\n",
        "    features=features,\n",
        ")\n",
        "\n",
        "test_sample = dataset[\"test\"].shuffle(seed=42).select(range(30))\n",
        "student_eval_dataset = test_sample.map(\n",
        "    student_prepare_examples,\n",
        "    batched=True,\n",
        "    remove_columns=column_names,\n",
        "    features=features,\n",
        ")\n",
        "\n",
        "validation_sample = dataset[\"test\"].shuffle(seed=42).select(range(10))\n",
        "student_validation_dataset = validation_sample.map(\n",
        "    student_prepare_examples,\n",
        "    batched=True,\n",
        "    remove_columns=column_names,\n",
        "    features=features,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAWWIkbmJ0DO"
      },
      "source": [
        "# 11. Load Student Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPTeinIoJ9Mt",
        "outputId": "efe070e1-3228-4013-ea88-7d898cafc40a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "student_model = DistilBertForTokenClassification.from_pretrained(\n",
        "    \"distilbert-base-uncased\",\n",
        "    num_labels=num_labels,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ").to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xTAbfqpBZP3"
      },
      "source": [
        "# 12. Define Distillation Loss\n",
        "\n",
        "* Compute KL divergence loss between teacher and student logits.\n",
        "\n",
        "* Use a weighted sum of soft (KL loss) and hard (cross-entropy) losses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwrTMwNXPX6i"
      },
      "outputs": [],
      "source": [
        "def distillation_loss(student_logits, teacher_logits, labels, attention_mask, temperature=2.0, alpha=0.8):\n",
        "    kl_loss_fn = nn.KLDivLoss(reduction=\"batchmean\")\n",
        "    ce_loss_fn = nn.CrossEntropyLoss()\n",
        "    mask = (labels != -100)\n",
        "    soft_loss = kl_loss_fn(\n",
        "        torch.log_softmax(student_logits[mask] / temperature, dim=-1),\n",
        "        torch.softmax(teacher_logits[mask] / temperature, dim=-1)\n",
        "    )\n",
        "    hard_loss = ce_loss_fn(student_logits[mask], labels[mask])\n",
        "    return alpha * soft_loss + (1 - alpha) * hard_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DU_cpIidBji6"
      },
      "source": [
        "# 13. Train the Student Model\n",
        " * Train the student model using knowledge distillation.\n",
        "\n",
        "* Extract logits from the teacher model and use them in loss computation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGc4XpR4PbUT",
        "outputId": "c2b4147f-8ec3-47f9-f540-c102b3ef5f42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 1:   7%|â–‹         | 1/15 [00:00<00:10,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/15 Loss: 0.5914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:10<00:00,  1.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Avg Loss: 0.4165\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 2:   7%|â–‹         | 1/15 [00:00<00:11,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/15 Loss: 0.5032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:09<00:00,  1.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 - Avg Loss: 0.4021\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 3:   7%|â–‹         | 1/15 [00:00<00:08,  1.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/15 Loss: 0.4598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:09<00:00,  1.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 - Avg Loss: 0.4030\n",
            "Epoch 4/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 4:   7%|â–‹         | 1/15 [00:00<00:08,  1.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/15 Loss: 0.3577\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:09<00:00,  1.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 - Avg Loss: 0.3956\n",
            "Epoch 5/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 5:   7%|â–‹         | 1/15 [00:00<00:08,  1.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/15 Loss: 0.3439\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:08<00:00,  1.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 - Avg Loss: 0.3973\n",
            "Epoch 6/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 6:   7%|â–‹         | 1/15 [00:00<00:09,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/15 Loss: 0.4473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:09<00:00,  1.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 - Avg Loss: 0.3967\n",
            "Epoch 7/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 7:   7%|â–‹         | 1/15 [00:00<00:08,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/15 Loss: 0.3972\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:09<00:00,  1.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 - Avg Loss: 0.3988\n",
            "Epoch 8/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 8:   7%|â–‹         | 1/15 [00:00<00:08,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/15 Loss: 0.2741\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:08<00:00,  1.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 - Avg Loss: 0.3962\n",
            "Epoch 9/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 9:   7%|â–‹         | 1/15 [00:00<00:09,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/15 Loss: 0.4085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:08<00:00,  1.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 - Avg Loss: 0.3948\n",
            "Epoch 10/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 10:   7%|â–‹         | 1/15 [00:00<00:08,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0/15 Loss: 0.3704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:09<00:00,  1.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 - Avg Loss: 0.3938\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def train_student_model(student_model, teacher_model, train_dataloader, optimizer, num_epochs=10, temperature=2.0, alpha=0.8):\n",
        "    student_model.train()\n",
        "    total_steps = len(train_dataloader)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss = 0\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "        for batch_idx, batch in enumerate(tqdm(train_dataloader, desc=f\"Processing Epoch {epoch+1}\")):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # The default_data_collator ensures uniform tensor shapes\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "            bbox = batch['bbox'].to(device)\n",
        "            pixel_values = batch['pixel_values'].to(device)\n",
        "\n",
        "            # Teacher forward pass (with no gradient)\n",
        "            with torch.no_grad():\n",
        "                teacher_outputs = teacher_model(\n",
        "                    input_ids=input_ids,\n",
        "                    attention_mask=attention_mask,\n",
        "                    bbox=bbox,\n",
        "                    pixel_values=pixel_values,\n",
        "                    labels=labels\n",
        "                )\n",
        "                teacher_logits = teacher_outputs.logits\n",
        "\n",
        "            # Student forward pass (text only)\n",
        "            student_outputs = student_model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                labels=labels\n",
        "            )\n",
        "            student_logits = student_outputs.logits\n",
        "\n",
        "            # Compute combined distillation loss\n",
        "            loss = distillation_loss(student_logits, teacher_logits, labels, attention_mask, temperature, alpha)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            if batch_idx % 100 == 0:\n",
        "                print(f\"Batch {batch_idx}/{total_steps} Loss: {loss.item():.4f}\")\n",
        "\n",
        "        avg_epoch_loss = epoch_loss / total_steps\n",
        "        print(f\"Epoch {epoch+1} - Avg Loss: {avg_epoch_loss:.4f}\")\n",
        "\n",
        "#########################################\n",
        "# 9. Set Up DataLoader and Optimizer    #\n",
        "#########################################\n",
        "\n",
        "# Use default_data_collator to ensure uniform tensor sizes\n",
        "train_dataloader = DataLoader(student_train_dataset, batch_size=4, shuffle=True, collate_fn=default_data_collator)\n",
        "optimizer = AdamW(student_model.parameters(), lr=2e-5)\n",
        "\n",
        "#########################################\n",
        "# 10. Start Training                    #\n",
        "#########################################\n",
        "\n",
        "train_student_model(student_model, teacher_model, train_dataloader, optimizer, num_epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMmpUgdJBySf"
      },
      "source": [
        "# 14. Evaluate and Save Student Model\n",
        "\n",
        "Use seqeval to measure precision, recall, and F1-score of the student model."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "student_model.save_pretrained(\"distilbert_student_model\")"
      ],
      "metadata": {
        "id": "pmjMoMyL8JKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1vbVJVcPemk",
        "outputId": "f73f358e-8841-4aa3-c7c3-68d80fb40ff8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  5.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'precision': np.float64(41.66666666666667), 'recall': np.float64(2.277904328018223), 'f1': np.float64(4.319654427645789), 'accuracy': 21.173814898419867}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "import evaluate\n",
        "\n",
        "def evaluate_student_model(student_model, eval_dataloader, label_list, device=\"cuda\"):\n",
        "    student_model.eval()\n",
        "    metric = evaluate.load(\"seqeval\")\n",
        "    true_predictions, true_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = student_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "            predictions = torch.argmax(logits, dim=-1).cpu().numpy()\n",
        "            label_ids = labels.cpu().numpy()\n",
        "\n",
        "            for prediction, label in zip(predictions, label_ids):\n",
        "                true_predictions.append([\n",
        "                    label_list[p] for p, l in zip(prediction, label) if l != -100\n",
        "                ])\n",
        "                true_labels.append([\n",
        "                    label_list[l] for p, l in zip(prediction, label) if l != -100\n",
        "                ])\n",
        "\n",
        "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "    overall_metrics = {\n",
        "        \"precision\": results[\"overall_precision\"]*100,\n",
        "        \"recall\": results[\"overall_recall\"]*100,\n",
        "        \"f1\": results[\"overall_f1\"]*100,\n",
        "        \"accuracy\": results[\"overall_accuracy\"]*100,\n",
        "    }\n",
        "\n",
        "    return overall_metrics\n",
        "\n",
        "# Example usage:\n",
        "eval_dataloader = DataLoader(student_validation_dataset, batch_size=4, collate_fn=default_data_collator)\n",
        "evaluation_results = evaluate_student_model(student_model, eval_dataloader, label_list)\n",
        "print(evaluation_results)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "device = \"cuda\"\n",
        "def evaluate_model(model, dataloader, device):\n",
        "    model.eval()\n",
        "    all_predictions, all_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            bbox = batch[\"bbox\"].to(device)\n",
        "            pixel_values = batch[\"pixel_values\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids,\n",
        "                            attention_mask=attention_mask,\n",
        "                            bbox=bbox,\n",
        "                            pixel_values=pixel_values)\n",
        "\n",
        "            logits = outputs.logits.detach().cpu().numpy()\n",
        "            label_ids = labels.detach().cpu().numpy()\n",
        "\n",
        "            predictions = np.argmax(logits, axis=2)\n",
        "\n",
        "            for pred, true_labels in zip(predictions, label_ids):\n",
        "                filtered_pred = [p for p, l in zip(pred, true_labels) if l != -100]\n",
        "                filtered_labels = [l for l in true_labels if l != -100]\n",
        "                all_predictions.extend(filtered_pred)\n",
        "                all_labels.extend(filtered_labels)\n",
        "\n",
        "    accuracy = accuracy_score(all_labels, all_predictions)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_predictions, average=\"macro\")\n",
        "\n",
        "    return {\"accuracy\": accuracy*100, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "eval_dataloader = DataLoader(validation_dataset, batch_size=4, collate_fn=default_data_collator)\n",
        "evaluation_results = evaluate_model(teacher_model, eval_dataloader, device)\n",
        "print(evaluation_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vHdFrFTJfmP",
        "outputId": "937ec90a-1031-450e-d220-157fd193102e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:1589: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'accuracy': 69.83016983016984, 'precision': 0.7645552881121446, 'recall': 0.780395810307793, 'f1': 0.7528805629617449}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ye11vOULUrKh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9cfc8df6e0ea45f78ffb71b25f1d8a50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_921cd6a9f2e343cbacb9fe93cd2fce44",
              "IPY_MODEL_1ee7a0949aa74a42bb503e05f7f3f6c5",
              "IPY_MODEL_39060935d34a453fa54bd246d4450a02"
            ],
            "layout": "IPY_MODEL_8136a9865583446bb190a0c04ae5c3d1"
          }
        },
        "921cd6a9f2e343cbacb9fe93cd2fce44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc6ef84d484541658c2a0b43a61748fc",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_bb25f853143141b1a2e6aba5e67cdac7",
            "value": "Map:â€‡100%"
          }
        },
        "1ee7a0949aa74a42bb503e05f7f3f6c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6df77999b95454689c4920c661ab563",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_90ce471dc88947aabf3d969ec0fc21f7",
            "value": 30
          }
        },
        "39060935d34a453fa54bd246d4450a02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c38d59a3f6945a6b06355b3608c20d0",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_686af2b5d76b4e4fa765f0b7a32f4fc8",
            "value": "â€‡30/30â€‡[00:01&lt;00:00,â€‡21.57â€‡examples/s]"
          }
        },
        "8136a9865583446bb190a0c04ae5c3d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc6ef84d484541658c2a0b43a61748fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb25f853143141b1a2e6aba5e67cdac7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6df77999b95454689c4920c661ab563": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90ce471dc88947aabf3d969ec0fc21f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c38d59a3f6945a6b06355b3608c20d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "686af2b5d76b4e4fa765f0b7a32f4fc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}